<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en"><head>
  <title>Aliasing is a Driver of Adversarial Attacks</title>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<meta property="og:title" content="Aliasing is a Driver of Adversarial Attacks" />
<script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>

<script src="lib.js" type="text/javascript"></script>
<script src="popup.js" type="text/javascript"></script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>

<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

<script type="text/javascript">
// redefining default features
var _POPUP_FEATURES = 'width=500,height=300,resizable=1,scrollbars=1,titlebar=1,status=1';
</script>
<link media="all" href="glab.css" type="text/css" rel="StyleSheet">
<style type="text/css" media="all">
IMG {
	PADDING-RIGHT: 0px;
	PADDING-LEFT: 0px;
	FLOAT: right;
	PADDING-BOTTOM: 0px;
	PADDING-TOP: 0px
}
#primarycontent {
	MARGIN-LEFT: auto; ; WIDTH: expression(document.body.clientWidth >
1000? "1000px": "auto" ); MARGIN-RIGHT: auto; TEXT-ALIGN: left; max-width:
1000px }
BODY {
	TEXT-ALIGN: center
}
</style>

<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 0px;
    width: 100%;
  }

  h1 {
    font-weight:300;
  }

  div {
    max-width: 95%;
    margin:auto;
    padding: 10px;
  }

  .table-like {
    display: flex;
    flex-wrap: wrap;
    flex-flow: row wrap;
    justify-content: center;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img {
    padding: 0;
    display: block;
    margin: 0 auto;
    /* max-height: 100%;
    max-width: 100%; */
  }

  iframe {
    max-width: 100%;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    max-width: 1100px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }

  #authors td {
    padding-bottom:5px;
    padding-top:30px;
  }
</style>

<body>

<div id="primarycontent">
<center><h1 style="font-size: 225%">Aliasing is a Driver of Adversarial Attacks</h1></center>
<center>
  <div class="table-like" style="justify-content:space-evenly;max-width:880px;margin:auto;">
    <div width="1"></div>
    <div>
      <center>
        <a href="adriarm.github.io" style="font-size: larger">Adrián Rodríguez-Muñoz</a>
      </center>
      <center>
        MIT CSAIL
      </center>
    </div>
    <div width="1"></div>
    <div>
      <center>
        <a href="https://web.mit.edu/torralba/www" style="font-size: larger">Antonio Torralba</a>
      </center>
      <center>
        MIT CSAIL
      </center>
    </div>
    <div width="1"></div>
  </div>
</center>
<!-- 
<center>
  <img class="result" src="files/simple_example.svg" style="width: 100">
</center> -->

<div class="table-like" style="justify-content:space-evenly;max-width:900px;margin:auto;">
  <center>
    <table>
      <tr>
        <td style="font-size:20px;margin:20px;font-family:monospace">
          <a style="margin:2px" href="files/paper.pdf">[Paper]</a>
        </td>
        <td style="font-size:20px;margin:20px;font-family:monospace">
          <!-- <a style="margin:2px" href="https://github.com/mbaradad/shaders21k">[Code]</a> -->
          [Code]
        </td>
      </tr>
    </table>
  </center>
</div>
<center>
<br>

<h2>Abstract</h2>
<div style="font-size:14px; text-align: justify;">
<p>
  Aliasing is a highly important concept in signal processing, as careful consideration of resolution changes is essential in ensuring 
  transmission and processing quality of audio, image, and video. Despite this, up until recently aliasing has received very little 
  consideration in Deep Learning, with all common architectures carelessly sub-sampling without considering aliasing effects. In this work, 
  we investigate the hypothesis that the existence of adversarial perturbations is due in part to aliasing in neural networks. Our ultimate goal is to increase robustness against adversarial attacks using explainable, non-trained, structural changes only, derived from aliasing 
  first principles.
</p>
<p>
  Our contributions are the following. First, we establish a sufficient condition for no aliasing for general image 
  transformations. Next, we study sources of aliasing in common neural network layers, and derive simple modifications from first principles 
  to eliminate or reduce it. Lastly, our experimental results show a solid link between anti-aliasing and adversarial attacks. Simply 
  reducing aliasing already results in more robust classifiers, and combining anti-aliasing with robust training out-performs solo 
  robust training on $L_2$ attacks with none or minimal losses in performance on $L_{\infty}$ attacks.
</p>
</div>


<hr>
<h2>What is aliasing?</h2>
<br>

<table border="0" cellspacing="0" cellpadding="0" width="900">
  <tr>
    <td align="center" valign="bottom" style="overflow:hidden;">
        <img class="result" src="files/simple_example.svg" style="width: 100%">
    </td>
  </tr>
</table>

<div style="text-align: justify;">
<p>
  The concept of aliasing is intrinsically related to discrete sampling. In layman's terms, the more ”complex” a continuous-domain signal, 
  the finer the sampling needed to properly represent it. Using an insufficiently fine sampling results in visual artifacts that perceptually 
  destroy the original signal; we call this phenomenon ”aliasing”. Consider the example shown in the above figure: the main ”feature” of the 
  signal, the right-to-left diagonals, is inverted by aliasing when sampling at an insufficient rate.
</p>
</div>


<hr>
<h2>Linking aliasing to adversarial examples</h2>
<br>

<table border="0" cellspacing="0" cellpadding="0" width="900">
  <tr>
    <td align="center" valign="bottom" style="overflow:hidden;">
        <img class="result" src="files/toy_example_2.svg" style="width: 100%">
    </td>
  </tr>
</table>

<div style="text-align: justify;">
<p>
  Our hypothesis is that adversarial attacks work in part by exploiting the phenomenon of aliasing. See the above 
  figure for a simple but enlightening toy example. As we can see, the dirty image is indistinguishable
  from the original clean image by a human, and yet their outputs are completely different. The culprit for this bizarre ef-
  fect is the convolution stride (green box) that carelessly down-samples the input. 
</p>
<p>
  An attacker with knowledge
  about it is able to construct a perturbation focused on manipulating the surviving samples (pixels at even rows and
  columns). The discarded samples (pixels at an odd row or column) serve as extra degrees of freedom that can be used
  to make the attack less noticeable and more powerful.
</p>
<p>  
  The behavior of these analytically constructed attacks is remarkably 
  similar to low-amplitude, gradient-driven attacks: they are imperceptible by humans and drastically change the feature maps of a network. 
  It is thus plausible that attacks may be exploiting aliasing.
</p>
</div>


<hr>
<h2>Neural Networks without aliasing</h2>
<br>

<table border="0" cellspacing="0" cellpadding="0" width="900">
  <tr>
    <td align="center" valign="bottom" style="overflow:hidden;">
        <img class="result" src="files/new_layer_cards_horizontal.svg" style="width: 100%">
    </td>
  </tr>
</table>

<div style="text-align: justify;">
<p>
  To supress aliasing in neural networks, we expand on existing blurring based approaches such as in [1, 2, 3] 
  by using theory to derive the exact blurring strength necessary, which coincides with the experimentally derived strength 
  as was done in [1]. Furthermore, we also introduce the Quantile ReLu anti-aliasing modification, which is a 
  new way of anti-aliasing independent of and synergistic with blurring-based approaches. The above figure shows 
  a summary graphic of the adaptations used in our experiments.
</p>

<p style="font-size:12px;text-align:left">
  [1] Tero Karras, Miika Aittala, Samuli Laine, Erik H ̈ark ̈onen,
  Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Alias-Free
  Generative Adversarial Networks. In Proc. NeurIPS, 2021 <br/>

  [2] Cristina Vasconcelos, Hugo Larochelle, Vincent Dumoulin,
  Rob Romijnders, Nicolas Le Roux, and Ross Goroshin.
  Impact of Aliasing on Generalization in Deep Convolu-
  tional Networks. In Proceedings of the IEEE/CVF In-
  ternational Conference on Computer Vision (ICCV), pages
  10529–10538, Oct. 2021. <br/>

  [3] Richard Zhang. Making Convolutional Networks Shift-
  Invariant Again. In ICML, 2019.
</p>
</div>


<hr>
<h2>How effective is anti-aliasing as a defense?</h2>
<br>

<table border="0" cellspacing="0" cellpadding="0" width="900">
  <tr>
    <td align="center" valign="bottom" style="overflow:hidden;">
        <img class="result" src="files/accuracy_amplitude.svg" style="width: 100%">
    </td>
  </tr>
</table>

<div style="text-align: justify;">
<p>
  The above figures compares the robustness of five defenses:
  <ul>
    <li>Vanilla: No defense.</li>
    <li>Initial Blur: Naive initial blur with [1 4 6 4 1]</li>
    <li>AA(5): Anti-aliasing all five blocks of the network.</li>
    <li>AT: Adversarial Training with PGD</li>
    <li>AT+AA(2): Combining adversarial training with anti-aliasing the first two blocks of the network.</li>
  </ul>
</p>
</div>
<hr>

<table>
  <tr>
    <td style="padding: 10px; padding-right: 50px">
      <span>
      <a href="https://arxiv.org/abs/2211.15120"><img style="float: left; max-width: 120%" alt="paper thumbnail" src="images/paper_thumbnail.png" width=200></a>
      </span>
    </td>
    <td>
      <span>
        <h2>Paper</h2>
        <p>
          Workshop on Symmetry and Geometry in Neural Representations at Conference on Neural Information Processing Systems (NeurIPS) 2022.
          <a href="https://arxiv.org/abs/2211.15120">arXiv 2211.15120</a>.
          <a href="https://openreview.net/forum?id=KRiST_rzkGl">OpenReview</a>.
        </p>

        <h2>Citation</h2>
        <p>Tongzhou Wang, Phillip Isola. "Improved Representation of Asymmetrical Distances with Interval Quasimetric Embeddings" <em>Workshop on Symmetry and Geometry in Neural Representations at Conference on Neural Information Processing Systems (NeurIPS)</em>. 2022.
        </p>
        <h2>Code:<span style="font-family:monospace;font-size:21px;margin:5px;position:relative;bottom:2px">
            <a style="font-weight:normal;" href="https://github.com/quasimetric-learning/torch-quasimetric">[PyTorch Package of SOTA Quasimetric Learning Methods]</a>
          </span></h2>
        <br>
      </span>
    </td>
  </tr>
</table>
<br>

<h3 style="margin-top: -1.6em;text-align:left"><code style="font-size: 15pt">bibtex</code> <span style="font-size: 14.5pt">entry</span></h3>
<div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;padding-right: 4em;width: 95%">
<pre style="font-size: 10pt; margin: .3em 0px;text-align: left">
@inproceedings{wang2022iqe,
  title={Improved Representation of Asymmetrical Distances with Interval Quasimetric Embeddings},
  author={Wang, Tongzhou and Isola, Phillip},
  note={Workshop on Symmetry and Geometry in Neural Representations at Conference on Neural Information Processing Systems (NeurIPS) 2022},
  booktitle={Proceedings of Machine Learning Research (PMLR)},
  volume={Volume on Symmetry and Geometry in Neural Representations},
  year={2022},
}
</pre>

</div>

<style type="text/css" media="all">
.page__footer {
  /*float: left;*/
  padding-top: 1em;
  padding-bottom: 0.5em;
  margin-left: 0;
  margin-right: 0;
  width: 100%;
  clear: both;
  /* sticky footer fix start */
  /*position: absolute;*/
  bottom: 0;
  height: auto;
  /* sticky footer fix end */
  margin-top: 3em;
  color: #898c8f;
  background-color: #f2f3f3;
  padding-left: 0em;
  padding-right: 0em;
  max-width: 100%;
}

.page__footer .links {
  margin-left: auto;
  margin-right: auto;
  max-width: 1000px;
  /*padding: 0;*/
}

.page__footer .links .social-icons {
  padding-left: 0;
  text-align: left;
}
</style>

<div class="page__footer">
  <div class="links">
    <ul class="social-icons">
      <li style='display: inline-block; margin-right: 5px; font-style: bold'><strong>Links:</strong></li>
      <li style='display: inline-block; margin-right: 5px; font-style: normal;'><a href="https://accessibility.mit.edu"><i class="fa fa-fw fas fa-universal-access" aria-hidden="true"></i> Accessibility</a></li>
    </ul>
  </div>
</div>

</body>

</html>